{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4 Retail Dashboard - Background Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    From this notebook, we perform our data cleaning & transforming:\n",
    "        - extracting raw data from directory:\n",
    "            - PLEASE NOTE: You must download raw files into a folder called 'raw' within the 'data' folder. Otherwise the pre-existing code won't work!\n",
    "        - extract additional files i.e. branch_expenses, product_list.\n",
    "            - PLEASE NOTE: these files must be separated from the raw data files into their own folder called 'other' within the 'data' folder. Otherwise the pre-existing code won't work!\n",
    "        - removing duplicates\n",
    "        - acquire product list\n",
    "        - acquire region list\n",
    "        - adding product category as a field\n",
    "        - adding region & county as separate fields\n",
    "        - cleaning of data:\n",
    "            - fix header to all match\n",
    "            - convert incorrect str dtypes to int or float\n",
    "        - save temporary csv file\n",
    "        - extract temp file using pandas\n",
    "        - add temp files data to pre-existing group dataframe\n",
    "        - save grouped dataframe\n",
    "        \n",
    "    This is done through an iteration of the raw directory. The iteration will be run 3 times. Each run through it dictated on the year the branch was established.\n",
    "\n",
    "    As the user of this script YOU MUST after every cycle adjust the name of the final save & the file range variable to the correct establishing year.\n",
    "    This will also be noted in the code itself.\n",
    "\n",
    "    Happy Coding!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up\n",
    "    - imports\n",
    "    - directory creation\n",
    "    - removal of duplicates\n",
    "    - acquisition of product & region lists\n",
    "    - created of empty dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import os\n",
    "import pandas as pd\n",
    "import petl as etl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_path = \"data/raw\"\n",
    "raw_data_directory = []\n",
    "\n",
    "for filename in os.listdir(raw_data_path):\n",
    "    file = os.path.join(raw_data_path, filename)\n",
    "\n",
    "    if os.path.isfile(file):\n",
    "        #print(file)\n",
    "        raw_data_directory.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_data_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove csv duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_data_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for file in raw_data_directory:\n",
    "    if str(file).endswith('json'):\n",
    "        if str(file).replace('json', 'csv') in raw_data_directory:\n",
    "            raw_data_directory.remove(str(file).replace('json', 'csv'))\n",
    "\n",
    "len(raw_data_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_data_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### acquire product list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Fairtrade Bananas Loose', 'fruits & vegetables'),\n",
       " ('British carrots loose', 'fruits & vegetables'),\n",
       " ('Onions Loose', 'fruits & vegetables'),\n",
       " ('British baking potatoes loose', 'fruits & vegetables'),\n",
       " ('Red pepper', 'fruits & vegetables'),\n",
       " ('Mixed pepper', 'fruits & vegetables'),\n",
       " ('Brocolli loose', 'fruits & vegetables'),\n",
       " ('Lemon', 'fruits & vegetables'),\n",
       " ('Spring onions bunch', 'fruits & vegetables'),\n",
       " ('Sweet potatoes loose', 'fruits & vegetables'),\n",
       " ('courgette loose', 'fruits & vegetables'),\n",
       " ('baby potatoes', 'fruits & vegetables'),\n",
       " ('british parsnips loose', 'fruits & vegetables'),\n",
       " ('fine beans', 'fruits & vegetables'),\n",
       " ('garlic', 'fruits & vegetables'),\n",
       " ('celery', 'fruits & vegetables'),\n",
       " ('aubergine', 'fruits & vegetables'),\n",
       " ('raspberries', 'fruits & vegetables'),\n",
       " ('british bramley cooking apples', 'fruits & vegetables'),\n",
       " ('easy peeler loose', 'fruits & vegetables'),\n",
       " ('scottish salmon', 'meat & fish'),\n",
       " ('beef mince', 'meat & fish'),\n",
       " ('british fresh chicken brest fillets', 'meat & fish'),\n",
       " ('british fresh chicken thigh fillets', 'meat & fish'),\n",
       " ('large king prawns', 'meat & fish'),\n",
       " ('cod fillets', 'meat & fish'),\n",
       " ('corned beef', 'meat & fish'),\n",
       " ('sea bass fillets', 'meat & fish'),\n",
       " ('diced chicken breast', 'meat & fish'),\n",
       " ('diced vernison', 'meat & fish'),\n",
       " ('chicken sausages', 'meat & fish'),\n",
       " ('beef sausages', 'meat & fish'),\n",
       " ('vernison sausages', 'meat & fish'),\n",
       " ('21 day mature rump steak', 'meat & fish'),\n",
       " ('21 day mature sirlion steak', 'meat & fish'),\n",
       " ('21 day mature ribeye steak', 'meat & fish'),\n",
       " ('salmon fillets', 'meat & fish'),\n",
       " ('british fresh turkey mince', 'meat & fish'),\n",
       " ('fresh turkey steak', 'meat & fish'),\n",
       " ('fresh whole turkey', 'meat & fish'),\n",
       " ('fresh whole chicken', 'meat & fish'),\n",
       " ('Almond milk', 'dairy'),\n",
       " ('Soy Milk', 'dairy'),\n",
       " ('Oats Milk', 'dairy'),\n",
       " ('Organic mILK', 'dairy'),\n",
       " ('Organic Kefir', 'dairy'),\n",
       " ('Plain Greek yoghurt', 'dairy'),\n",
       " ('Blueberry yoghurt', 'dairy'),\n",
       " ('Slightly salted butter', 'dairy'),\n",
       " ('unsalted butter', 'dairy'),\n",
       " ('mature cheddar cheese', 'dairy'),\n",
       " ('mild cheddar cheese', 'dairy'),\n",
       " ('free range large eggs x12', 'dairy'),\n",
       " ('organic raspberry yoghurt', 'dairy'),\n",
       " ('organic soured cream', 'dairy'),\n",
       " ('vanilla yoghurt', 'dairy'),\n",
       " ('semi skimmed milk', 'dairy'),\n",
       " ('skimmed milk', 'dairy'),\n",
       " ('blue stilton cheese', 'dairy'),\n",
       " ('goat cheese', 'dairy'),\n",
       " ('olive oil spread', 'dairy'),\n",
       " ('play station 3', 'gaming'),\n",
       " ('x-box 360', 'gaming'),\n",
       " ('gameboy color', 'gaming'),\n",
       " ('gameboy advance', 'gaming'),\n",
       " ('dual shock controller', 'gaming'),\n",
       " ('gaming mouse', 'gaming'),\n",
       " ('gaming keyboard', 'gaming'),\n",
       " ('minecraft game - xbox', 'gaming'),\n",
       " ('pokemon red', 'gaming'),\n",
       " ('pokemon blue', 'gaming'),\n",
       " ('pokemon gold', 'gaming'),\n",
       " ('pokemon yellow', 'gaming'),\n",
       " ('god of war 2', 'gaming'),\n",
       " ('halo combat evolved', 'gaming'),\n",
       " ('hp dv 2000 laptop', 'computing'),\n",
       " ('hp dv 3000 laptop', 'computing'),\n",
       " ('hp envy laptop', 'computing'),\n",
       " ('dell inspiron laptop', 'computing'),\n",
       " ('apple macbook pro mid 2009', 'computing'),\n",
       " ('apple macbook air mid 2009', 'computing'),\n",
       " ('dyson tower fan', 'appliances'),\n",
       " ('dyson vacuum cleaner', 'appliances'),\n",
       " ('dyson washing machine', 'appliances'),\n",
       " ('bosch washing machine', 'appliances'),\n",
       " ('lg washing machine', 'appliances'),\n",
       " ('samsung washing machine', 'appliances'),\n",
       " ('hotpoint washing machine', 'appliances'),\n",
       " ('jam doughnut', 'bakery'),\n",
       " ('custard doughnut', 'bakery'),\n",
       " ('croisant ', 'bakery'),\n",
       " ('almond croisant', 'bakery'),\n",
       " ('pain au chocolate', 'bakery'),\n",
       " ('pain au raisins', 'bakery'),\n",
       " ('chocolate twist', 'bakery'),\n",
       " ('shortbread', 'bakery'),\n",
       " ('millionaire square', 'bakery'),\n",
       " ('cheese cake', 'bakery'),\n",
       " ('chocolate fudge cake', 'bakery'),\n",
       " ('red velvet cake', 'bakery'),\n",
       " ('macaron - x3', 'bakery'),\n",
       " ('flapjack', 'bakery'),\n",
       " ('denim jeams', 'clothing'),\n",
       " ('denim jacket', 'clothing'),\n",
       " ('brenton t-shirt', 'clothing'),\n",
       " ('white shirt', 'clothing'),\n",
       " ('linen trousers', 'clothing'),\n",
       " ('linen shirt', 'clothing'),\n",
       " ('silk tie', 'clothing'),\n",
       " ('cotton tie', 'clothing'),\n",
       " ('oxford shirt', 'clothing'),\n",
       " ('brenton jumper', 'clothing'),\n",
       " ('silk scarf', 'clothing'),\n",
       " ('plastic sunshades', 'clothing'),\n",
       " ('wellington boots', 'clothing'),\n",
       " ('oxford shoes', 'clothing'),\n",
       " ('wristwatch', 'clothing'),\n",
       " ('classic bowtie', 'clothing'),\n",
       " ('grey blazers', 'clothing'),\n",
       " ('grey cardigan', 'clothing'),\n",
       " ('pink blazers', 'clothing')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# acquire product list from directory\n",
    "product_list = list(\n",
    "    etl.fromcsv('data/other/products_list.csv')\\\n",
    "        .values('product', 'category'))\n",
    "        \n",
    "# print for checking\n",
    "product_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### acquire region list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('East of England', 'Bedfordshire', 'Bedfordshire store'),\n",
       " ('East of England', 'East Cambridgeshire', 'East Cambridgeshire outlet'),\n",
       " ('West Midlands', 'Warwickshire', 'Warwickshire branch'),\n",
       " ('East Midlands', 'Lincolnshire', 'Lincolnshire store'),\n",
       " ('London', 'Islington', 'Islington branch'),\n",
       " ('North East England', 'Stockton-on-Tees', 'Stockton-on-Tees store'),\n",
       " ('Northern Ireland', 'Belfast', 'Belfast branch'),\n",
       " ('North West England', 'Wyre', 'Wyre branch'),\n",
       " ('South East England', 'Mole Valley', 'Mole Valley store'),\n",
       " ('Scotland', 'Orkney', 'Orkney store'),\n",
       " ('South West England', 'Dorset', 'Dorset outlet'),\n",
       " ('East Midlands', 'Nottinghamshire', 'Nottinghamshire store'),\n",
       " ('Yorkshire and the Humber', 'North Yorkshire', 'North Yorkshire outlet'),\n",
       " ('South East England', 'Reigate and Banstead', 'Reigate and Banstead branch'),\n",
       " ('South East England', 'Epsom and Ewell', 'Epsom and Ewell store'),\n",
       " ('Wales', 'Wrexham', 'Wrexham store'),\n",
       " ('Wales', 'Isle of Anglesey', 'Isle of Anglesey outlet'),\n",
       " ('West Midlands', 'Warwickshire', 'Warwickshire branch'),\n",
       " ('Wales', 'Bridgend', 'Bridgend outlet'),\n",
       " ('Scotland', 'Edinburgh City', 'Edinburgh City branch'),\n",
       " ('South East England', 'Isle of Wight', 'Isle of Wight store'),\n",
       " ('East of England', 'Colchester', 'Colchester outlet'),\n",
       " ('East of England', 'Uttlesford', 'Uttlesford branch'),\n",
       " ('Scotland', 'Glasgow City', 'Glasgow City outlet'),\n",
       " ('Wales', 'Neath Port Talbot', 'Neath Port Talbot outlet'),\n",
       " ('East of England', 'East Cambridgeshire', 'East Cambridgeshire outlet'),\n",
       " ('South West England', 'Forest of Dean', 'Forest of Dean store'),\n",
       " ('East Midlands', 'Rushcliffe', 'Rushcliffe branch'),\n",
       " ('Wales', 'Neath Port Talbot', 'Neath Port Talbot outlet'),\n",
       " ('Wales', 'Ceredigion', 'Ceredigion store'),\n",
       " ('East of England', 'Castle Point', 'Castle Point outlet'),\n",
       " ('East Midlands', 'East Lindsey', 'East Lindsey branch'),\n",
       " ('London', 'Haringey', 'Haringey store'),\n",
       " ('East Midlands', 'East Lindsey', 'East Lindsey branch'),\n",
       " ('London', 'Greater London', 'Greater London branch'),\n",
       " ('South East England', 'Oxford', 'Oxford outlet'),\n",
       " ('Wales', 'Flintshire', 'Flintshire branch'),\n",
       " ('London', 'Hackney', 'Hackney store'),\n",
       " ('North East England', 'Darlington', 'Darlington store'),\n",
       " ('North West England', 'Fylde', 'Fylde outlet'),\n",
       " ('South East England', 'Shepway', 'Shepway store'),\n",
       " ('South East England', 'Bracknell Forest', 'Bracknell Forest store'),\n",
       " ('Scotland', 'East Dunbartonshire', 'East Dunbartonshire branch'),\n",
       " ('West Midlands', 'Lichfield', 'Lichfield outlet'),\n",
       " ('South East England', 'Sevenoaks', 'Sevenoaks branch'),\n",
       " ('London', 'Islington', 'Islington branch'),\n",
       " ('London', 'Greater London', 'Greater London branch'),\n",
       " ('Yorkshire and the Humber', 'Richmondshire', 'Richmondshire outlet'),\n",
       " ('West Midlands', 'Rugby', 'Rugby branch'),\n",
       " ('East Midlands', 'Hinckley and Bosworth', 'Hinckley and Bosworth branch'),\n",
       " ('Wales', 'Powys', 'Powys outlet'),\n",
       " ('East Midlands', 'Lincoln', 'Lincoln branch'),\n",
       " ('South East England', 'West Oxfordshire', 'West Oxfordshire outlet'),\n",
       " ('North West England', 'Lancashire', 'Lancashire store'),\n",
       " ('South East England', 'Fareham', 'Fareham outlet'),\n",
       " ('Wales', 'Swansea', 'Swansea store'),\n",
       " ('North West England', 'Chorley', 'Chorley store'),\n",
       " ('South West England', 'West Somerset', 'West Somerset branch'),\n",
       " ('Scotland', 'Falkirk', 'Falkirk branch'),\n",
       " ('South East England', 'East Sussex', 'East Sussex outlet'),\n",
       " ('London', 'Lambeth', 'Lambeth store'),\n",
       " ('East of England', 'Norfolk', 'Norfolk outlet'),\n",
       " ('Scotland', 'Edinburgh City', 'Edinburgh City branch'),\n",
       " ('East of England', 'East Hertfordshire', 'East Hertfordshire branch'),\n",
       " ('Wales', 'Rhoose', 'Rhoose branch'),\n",
       " ('East Midlands', 'East Lindsey', 'East Lindsey branch'),\n",
       " ('London', 'Newham', 'Newham branch'),\n",
       " ('North East England', 'Tyne and Wear', 'Tyne and Wear outlet'),\n",
       " ('West Midlands', 'Staffordshire', 'Staffordshire store'),\n",
       " ('Scotland', 'Peeblesshire', 'Peeblesshire outlet'),\n",
       " ('London', 'Harrow', 'Harrow outlet'),\n",
       " ('Northern Ireland', 'Armagh', 'Armagh outlet'),\n",
       " ('Scotland', 'Dumfries and Galloway', 'Dumfries and Galloway branch'),\n",
       " ('Yorkshire and the Humber', 'York', 'York outlet'),\n",
       " ('Northern Ireland', 'Ballymoney', 'Ballymoney store'),\n",
       " ('Wales', 'Barry', 'Barry outlet'),\n",
       " ('North West England', 'Cheshire East', 'Cheshire East outlet'),\n",
       " ('North West England', 'Sefton', 'Sefton outlet'),\n",
       " ('East of England', 'Bedford Borough', 'Bedford Borough branch'),\n",
       " ('Scotland', 'Falkirk', 'Falkirk branch'),\n",
       " ('East Midlands', 'Bassetlaw', 'Bassetlaw outlet'),\n",
       " ('East of England', 'St. Edmundsbury', 'St. Edmundsbury branch'),\n",
       " ('Northern Ireland', 'Larne', 'Larne store'),\n",
       " ('Wales', 'Bargoed', 'Bargoed outlet'),\n",
       " ('West Midlands', 'Stoke-on-Trent', 'Stoke-on-Trent store'),\n",
       " ('Yorkshire and the Humber', 'Selby', 'Selby branch'),\n",
       " ('Scotland', 'North Ayrshire', 'North Ayrshire store'),\n",
       " ('South West England', 'East Devon', 'East Devon branch'),\n",
       " ('Scotland', 'Falkirk', 'Falkirk branch'),\n",
       " ('Yorkshire and the Humber', 'North Yorkshire', 'North Yorkshire store'),\n",
       " ('East Midlands', 'Newark and Sherwood', 'Newark and Sherwood store'),\n",
       " ('South East England', 'Kent', 'Kent branch'),\n",
       " ('Scotland', 'Orkney', 'Orkney store'),\n",
       " ('West Midlands', 'Worcestershire', 'Worcestershire branch'),\n",
       " ('South East England', 'Hampshire', 'Hampshire branch'),\n",
       " ('South East England', 'Kent', 'Kent branch'),\n",
       " ('South East England', 'Chiltern', 'Chiltern store'),\n",
       " ('East Midlands', 'South Northamptonshire', 'South Northamptonshire store'),\n",
       " ('South West England', 'West Somerset', 'West Somerset branch'),\n",
       " ('Wales', 'Wrexham', 'Wrexham store')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# acquire branch list from directory\n",
    "branch_list = list(\n",
    "    etl.fromxlsx('data/other/branch_list.xlsx')\\\n",
    "        .values('region', 'county', 'branch_name'))\n",
    "\n",
    "\n",
    "\n",
    "# print for checking\n",
    "branch_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creation of blank dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_branches_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup & Transform Functions\n",
    "    - adding the product category as a field\n",
    "    - adding region & county as separate fields\n",
    "    - cleanup of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adding product category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add product category function\n",
    "def add_product_category(prv, cur, nxt):\n",
    "    for row in product_list:\n",
    "        if cur.product == row[0]:\n",
    "            return row[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adding region & city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add region & city function\n",
    "def add_region_city(table, file):\n",
    "    # acquire city name from file\n",
    "    branch_name = str(file).split('_', 1).pop(1)\\\n",
    "        .rsplit('.', 1).pop(0)\\\n",
    "        .replace('_', ' ')\n",
    "    # check through branch list for a match\n",
    "    for row in branch_list:\n",
    "        if branch_name == row[2]:\n",
    "            table = etl.addfields(table, [('county', row[1]), ('region', row[0])])\n",
    "            return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cleanup\n",
    "    - fix any miss matched headers\n",
    "    - convert incorrect dtypes to appropriate ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fix headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_headers(table):\n",
    "    \n",
    "# if table has the header sku or item.. change to product\n",
    "    if 'sku' in etl.header(table):\n",
    "        table = etl.rename(\n",
    "                        table, \n",
    "                        'sku', 'product')\n",
    "    elif 'item' in etl.header(table):\n",
    "        table = etl.rename(\n",
    "                        table, \n",
    "                        'item', 'product')\n",
    "\n",
    "# rename header to only have the one name (total_quantity_purchase)\n",
    "    if 'quantity' in etl.header(table):\n",
    "        table = etl.rename(\n",
    "                        table,\n",
    "                        'quantity', 'total_quantity_purchased'\n",
    "    )\n",
    "    elif 'total_quantity' in etl.header(table):\n",
    "        table = etl.rename(\n",
    "                        table,\n",
    "                        'total_quantity', 'total_quantity_purchased'\n",
    "    )\n",
    "    elif 'quantity_purchased' in etl.header(table):\n",
    "        table = etl.rename(\n",
    "                        table,\n",
    "                        'quantity_purchased', 'total_quantity_purchased'\n",
    "    )\n",
    "\n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dtype conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_conversion(table):\n",
    "    # convert field to int\n",
    "    table = etl.convert(\n",
    "                    table, \n",
    "                    ['total_quantity_purchased'],\n",
    "                    int)\n",
    "\n",
    "# convert field to float\n",
    "# round up field to 2 decimal points\n",
    "    table = etl.convert(\n",
    "                    table, \n",
    "                    'amount_in_gbp',\n",
    "                    lambda cell: round(float(cell), 2))\n",
    "\n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterating Through Files\n",
    "    - PLEASE NOTE: \n",
    "        This is a piece of script that needs to be run 3 times. Each time changing the file_range variable which can be seen in the next cell to the next year branches were established.\n",
    "        Essentially... it is first set to 2010... after it has run adjust this to 2011 and after that 2012\n",
    "\n",
    "        DON'T FORGET to also adjust the save file's name to the corresponding year! Otherwise something won't quite work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/raw\\2012-2020_Armagh_outlet.csv\n",
      "data/raw\\2012-2020_Ballymoney_store.csv\n",
      "data/raw\\2012-2020_Bargoed_outlet.json\n",
      "data/raw\\2012-2020_Bedfordshire_store.json\n",
      "data/raw\\2012-2020_Colchester_outlet.json\n",
      "data/raw\\2012-2020_Darlington_store.csv\n",
      "data/raw\\2012-2020_East_Dunbartonshire_branch.json\n",
      "data/raw\\2012-2020_East_Hertfordshire_branch.json\n",
      "data/raw\\2012-2020_Edinburgh_City_branch.json\n",
      "data/raw\\2012-2020_Glasgow_City_outlet.csv\n",
      "data/raw\\2012-2020_Hackney_store.csv\n",
      "data/raw\\2012-2020_Isle_of_Anglesey_outlet.json\n",
      "data/raw\\2012-2020_Lancashire_store.json\n",
      "data/raw\\2012-2020_Lincolnshire_store.json\n",
      "data/raw\\2012-2020_Neath_Port_Talbot_outlet.json\n",
      "data/raw\\2012-2020_Newark_and_Sherwood_store.json\n",
      "data/raw\\2012-2020_Reigate_and_Banstead_branch.csv\n",
      "data/raw\\2012-2020_Rugby_branch.json\n",
      "data/raw\\2012-2020_Rushcliffe_branch.csv\n",
      "data/raw\\2012-2020_Selby_branch.json\n",
      "data/raw\\2012-2020_Sevenoaks_branch.csv\n",
      "data/raw\\2012-2020_Shepway_store.csv\n",
      "data/raw\\2012-2020_Stockton-on-Tees_store.csv\n",
      "data/raw\\2012-2020_Uttlesford_branch.json\n",
      "data/raw\\2012-2020_West_Oxfordshire_outlet.csv\n",
      "data/raw\\2012-2020_Worcestershire_branch.csv\n",
      "data/raw\\2012-2020_Wrexham_store.json\n",
      "data/raw\\2012-2020_York_outlet.json\n"
     ]
    }
   ],
   "source": [
    "# set of files to work on through this iteration\n",
    "# PLEASE CHANGE THIS TO 2011 AND 2012 FOR THE NEXT TWO RUN THROUGHS\n",
    "file_range = \"2010\"\n",
    "# for each file in the directory\n",
    "for file in raw_data_directory:\n",
    "\n",
    "        if str(file).split('-').pop(0).endswith(file_range):\n",
    "                print(file)\n",
    "# check if csv file type\n",
    "                if str(file).endswith('csv'):\n",
    "# extract from said type\n",
    "                        current_table = etl.fromcsv(file)\n",
    "# initiate cleanup functions\n",
    "# fix miss labelled headers\n",
    "                        current_table = fix_headers(current_table)\n",
    "\n",
    "# convert field types from string to number\n",
    "                        current_table = str_conversion(current_table)\n",
    "\n",
    "# adding product categories to current_table\n",
    "                        current_table = etl.addfieldusingcontext(current_table, 'product_category', add_product_category)\n",
    "\n",
    "# adding region & city\n",
    "                        current_table = add_region_city(current_table, file)\n",
    "\n",
    "# save temp file\n",
    "                        current_table.tocsv('temp_branch.csv')\n",
    "\n",
    "# extract file using pandas\n",
    "                        current_df = pd.read_csv('temp_branch.csv')\n",
    "\n",
    "# append the current df to the total df for branches\n",
    "                        all_branches_df = all_branches_df.append(current_df, ignore_index=True)\n",
    "              \n",
    "# in case of other file type\n",
    "                else:\n",
    "# extract from json file type\n",
    "                        current_table = etl.fromjson(file)\n",
    "# initiate cleanup functions\n",
    "# fix miss labelled headers\n",
    "                        current_table = fix_headers(current_table)\n",
    "\n",
    "# convert field types from string to number\n",
    "                        current_table = str_conversion(current_table)\n",
    "\n",
    "# adding product categories to current_table\n",
    "                        current_table = etl.addfieldusingcontext(current_table, 'product_category', add_product_category)\n",
    "\n",
    "# adding region & city\n",
    "                        current_table = add_region_city(current_table, file)\n",
    "\n",
    "# save file\n",
    "                        current_table.tocsv('temp_branch.csv')\n",
    "\n",
    "# extract as df\n",
    "                        current_df = pd.read_csv('temp_branch.csv')\n",
    "                \n",
    "# append the current df to the total df for branches\n",
    "                        all_branches_df = all_branches_df.append(current_df, ignore_index=True)\n",
    "                      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save\n",
    "    - please note after each run through to change the year at the end of the file name to the correct establishing year... otherwise the code won't quite work!\n",
    "    - also please don't forget to create the refined directory beforehand... otherwise an error will occur!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_branches_df.to_csv('data/refined/branches_established_in_2010.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "897084670679e532d4747db6e12278e58d6a827e24a9875614577ac8acaafdb5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('.env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
